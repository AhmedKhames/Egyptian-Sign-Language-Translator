{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "\n",
    "base_model = ResNet50(weights='imagenet',include_top=False, input_shape=(HEIGHT, WIDTH, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'output/train'\n",
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_datagen =  ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_DIR = 'output/val'\n",
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "val_datagen =  ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(VAL_DIR, \n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        # New FC layer, random init\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # New softmax layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x) \n",
    "    \n",
    "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return finetune_model\n",
    "\n",
    "class_list = [\"ana\",\"close\",\"continue\",\"eat\",\"fen\",\"listen\",\"open\",\"short\",\n",
    "              \"tall\",\"watch\"]\n",
    "FC_LAYERS = [1024, 1024]\n",
    "dropout = 0.5\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      fc_layers=FC_LAYERS,\n",
    "                                      num_classes=len(class_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "num_train_images = 15039\n",
    "num_val_images = 2816 \n",
    "\n",
    "adam = Adam(lr=0.00001)\n",
    "model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath=\"/content/drive/My Drive/\" + \"New_ResNet50_model_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=NUM_EPOCHS, workers=8, \n",
    "                                       steps_per_epoch=num_train_images // BATCH_SIZE,\n",
    "                                       validation_data=val_generator, \n",
    "                                       validation_steps=num_val_images // BATCH_SIZE,\n",
    "                                       shuffle=True, callbacks=callbacks_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
